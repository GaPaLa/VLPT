{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2969,
     "status": "ok",
     "timestamp": 1669722448788,
     "user": {
      "displayName": "Idmi",
      "userId": "02220947904692487762"
     },
     "user_tz": 0
    },
    "id": "nbezCFQUbal_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gppl20\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import sys, os\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "import minerl\n",
    "\n",
    "#from data_loader import DataLoader\n",
    "from lib.tree_util import tree_map\n",
    "\n",
    "if th.cuda.is_available():\n",
    "    DEVICE = th.device('cuda')\n",
    "    print(\"USING CUDA\")\n",
    "else:\n",
    "\n",
    "    DEVICE = th.device('cpu')\n",
    "    print(\"USING CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import TransfoXLTokenizer\n",
    "text = \"Well, if my name were Daniel, I would certainly not be joking about it so much. As it stands, I am not named Daniel, and so find it perfectly apt to mock you.\"\n",
    "\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained(\"transfo-xl-wt103\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([240])\n",
      "1 torch.Size([240])\n",
      "2 torch.Size([48, 5])\n",
      "3 torch.Size([48, 5])\n",
      "final 12\n",
      "{'input_ids': tensor([[ 6415,     2,   222,   617,   237,    28,  2452,     2,    68,    61,\n",
      "          4867,    38,    35, 27875,    80,    29,   138,   220,     3,   147,\n",
      "            29,  3024,     2,    68,  2271,    38,   249,  2452,     2,     5,\n",
      "           138,   767,    29,  7116, 28661,     6, 10966,   304,     3]])}\n",
      "Well, if my name were Daniel, I would certainly not be joking about it so much. As it stands, I am not named Daniel, and so find it perfectly apt to mock you.\n",
      "<eos>\n",
      "WARNING: USING CUSTOM TRANSFORMER_XL UTILITIES.py. DO NOT USE THE LMHEAD.FORWAD() METHOD IWTH LABELS, IT WILL GIVE INCORRECT LOSS AND PREDICTIONS\n",
      "logits tensor([[ -7.3768,  -4.0480,  -3.6218,  ..., -18.7565, -18.9308, -18.8882],\n",
      "        [ -2.2302,  -3.4663,  -3.5769,  ..., -16.8529, -16.6243, -16.0952],\n",
      "        [-11.5055,  -3.2825,  -6.6499,  ..., -18.9755, -20.5230, -18.4249],\n",
      "        ...,\n",
      "        [ -8.6760,  -1.9662,  -4.1156,  ..., -20.2708, -20.0940, -18.7047],\n",
      "        [ -8.4901,  -6.4914,  -2.0714,  ..., -22.3452, -21.8349, -20.8560],\n",
      "        [ -2.3459,  -3.8325,  -3.5754,  ..., -16.6095, -16.4205, -15.8427]],\n",
      "       grad_fn=<CopySlices>)\n",
      "loss tensor(8.7466, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 39])\n",
      "torch.Size([39])\n",
      "Well, if my name were Daniel, I would certainly not be joking about it so much. As it stands, I am not names Daniel, and so find it perfectly apt to mock you. \n",
      "\n",
      "well <eos> not own is to Defoe I would have be be Daniel. it. I that <eos> a turned, it would not joking., I I I myself amusing appropriate to be the. <eos>\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"= = Distribution = =\n",
    "Species range across the Neotropics from Mexico in the north to Bolivia, Paraguay, and southern Brazil in the south. According to <unk> and coauthors, three\n",
    "species are found in Mexico, four in Central America, and 62 in South America. Three species are present in the Caribbean â€” two in Trinidad and Tobago, along\n",
    "the southern edge of the region, and one in Haiti.\"\"\"\n",
    "import numpy as np\n",
    "path = 'text.txt'\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        if True and idx > 0 and idx % 500000 == 0:\n",
    "            pass\n",
    "            #print('    line {}'.format(idx))\n",
    "        #print('LINE',line)\n",
    "\n",
    "\n",
    "data = th.LongTensor(np.arange(5*16*3))\n",
    "\n",
    "bsz = 5\n",
    "bptt = 4\n",
    "ext_len = 0\n",
    "\n",
    "# Work out how cleanly we can divide the dataset into bsz parts.\n",
    "print('0',data.shape)\n",
    "n_step = data.size(0) // bsz\n",
    "\n",
    "# Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "data = data.narrow(0, 0, n_step * bsz)\n",
    "print('1',data.shape)\n",
    "\n",
    "\n",
    "# Evenly divide the data across the bsz batches.\n",
    "data = data.view(bsz, -1).t().contiguous()\n",
    "print('2',data.shape)\n",
    "\n",
    "# Number of mini-batches\n",
    "n_batch = (n_step + bptt - 1) // bptt\n",
    "print('3',data.shape)\n",
    "\n",
    "print('final', n_batch)\n",
    "\n",
    "# LOAD TOKENIZER\n",
    "from transformers import TransfoXLTokenizer\n",
    "text = \"Well, if my name were Daniel, I would certainly not be joking about it so much. As it stands, I am not named Daniel, and so find it perfectly apt to mock you.\"\n",
    "\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained(\"transfo-xl-wt103\")\n",
    "## TEST TOKENIZER\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "n_tokens = inputs['input_ids'].shape[1]\n",
    "print(inputs)\n",
    "inputs_list = inputs['input_ids'].reshape([n_tokens]).tolist()\n",
    "print(tokenizer.decode(inputs_list))\n",
    "print(tokenizer.decode([0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#LOAD LM\n",
    "from transformers import TransfoXLLMHeadModel\n",
    "model = TransfoXLLMHeadModel.from_pretrained(\"transfo-xl-wt103\")\n",
    "\n",
    "if False:\n",
    "    print(model.transformer.d_embed)\n",
    "    print(model.transformer.n_layer)\n",
    "    print(model.transformer.n_head)\n",
    "    print(model.transformer.d_model)\n",
    "    print(model.transformer.config.bos_token_id)\n",
    "    print(model.transformer.config.vocab_size)\n",
    "    print(model.sample_softmax)\n",
    "    print(model.transformer.config.div_val)\n",
    "    print(model.transformer.word_emb)\n",
    "    print(model.transformer.word_emb)\n",
    "\n",
    "    print(model.config.torchscript)\n",
    "    print(model.trainer_compatible)\n",
    "\n",
    "\n",
    "    print(model.num_parameters())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#outputs = model(inputs_embeds=torch.normal(0,1,[1,5,1024]))\n",
    "input_ids = th.tensor([[6415,     2,   222,   617,   237,    28,  2452,     2,    68,    61,\n",
    "          4867,    38,    35, 27875,    80,    29,   138,   220,     3,   147,\n",
    "            29,  3024,     2,    68,  2271,    38,  1302,  2452,     2,     5,\n",
    "           138,   767,    29,  7116, 28661,     6, 10966,   304,     3]],\n",
    "            dtype=th.long)\n",
    "\n",
    "outputs = model(input_ids=input_ids, labels=input_ids.roll(1, dims=1))\n",
    "#outputs2 = model(input_ids=input_ids, labels=input_ids)\n",
    "\n",
    "#\n",
    "\n",
    "#print(tokenizer.decode(outputs.prediction_scores[0,5,1000]))\n",
    "\n",
    "\n",
    "\n",
    "#print(outputs)\n",
    "print('logits',outputs.logits)\n",
    "print('loss',outputs.loss)\n",
    "\n",
    "maxes = th.argmax(outputs.logits, axis=1)\n",
    "print(input_ids.shape)\n",
    "print(maxes.shape)\n",
    "print(tokenizer.decode(input_ids[0]),\"\\n\")\n",
    "print(tokenizer.decode(maxes))\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "error",
     "timestamp": 1669722218180,
     "user": {
      "displayName": "Idmi",
      "userId": "02220947904692487762"
     },
     "user_tz": 0
    },
    "id": "Wfv11S7AjPbo",
    "outputId": "dea05d6d-d32f-4dbd-fbf1-398affc96078"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\gppl20\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\minerl\\\\env\\\\Malmo\\\\Minecraft'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\VLPT\\VLPT\\VLPT explorer.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VLPT/VLPT/VLPT%20explorer.ipynb#ch0000003?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39magent\u001b[39;00m \u001b[39mimport\u001b[39;00m PI_HEAD_KWARGS, MineRLAgent\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VLPT/VLPT/VLPT%20explorer.ipynb#ch0000003?line=10'>11</a>\u001b[0m agent_policy_kwargs, agent_pi_head_kwargs \u001b[39m=\u001b[39m load_model_parameters(\u001b[39m\"\u001b[39m\u001b[39m2x.model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/VLPT/VLPT/VLPT%20explorer.ipynb#ch0000003?line=12'>13</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(\u001b[39m\"\u001b[39;49m\u001b[39mMineRLNavigate-v0\u001b[39;49m\u001b[39m\"\u001b[39;49m)  \u001b[39m# MineRLObtainTest-v0  #'MineRLTreechop-v0' #MINERL_NAVIGATE_V0 #MINERL_OBTAIN_DIAMOND_V0 #MINERL_OBTAIN_IRON_PICKAXE_V0 #\"MineRLBasaltFindCave-v0\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VLPT/VLPT/VLPT%20explorer.ipynb#ch0000003?line=13'>14</a>\u001b[0m agent \u001b[39m=\u001b[39m MineRLAgent(env\u001b[39m=\u001b[39menv, device\u001b[39m=\u001b[39mDEVICE, policy_kwargs\u001b[39m=\u001b[39magent_policy_kwargs, pi_head_kwargs\u001b[39m=\u001b[39magent_pi_head_kwargs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VLPT/VLPT/VLPT%20explorer.ipynb#ch0000003?line=14'>15</a>\u001b[0m env\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\envs\\registration.py:184\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake\u001b[39m(\u001b[39mid\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39mmake(\u001b[39mid\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\envs\\registration.py:106\u001b[0m, in \u001b[0;36mEnvRegistry.make\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mMaking new env: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, path)\n\u001b[0;32m    105\u001b[0m spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspec(path)\n\u001b[1;32m--> 106\u001b[0m env \u001b[39m=\u001b[39m spec\u001b[39m.\u001b[39mmake(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m \u001b[39m# We used to have people override _reset/_step rather than\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m# reset/step. Set _gym_disable_underscore_compat = True on\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39m# your environment if you use these methods and don't want\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39m# compatibility code to be invoked.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    112\u001b[0m     \u001b[39mhasattr\u001b[39m(env, \u001b[39m\"\u001b[39m\u001b[39m_reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(env, \u001b[39m\"\u001b[39m\u001b[39m_step\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(env, \u001b[39m\"\u001b[39m\u001b[39m_gym_disable_underscore_compat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    115\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\envs\\registration.py:76\u001b[0m, in \u001b[0;36mEnvSpec.make\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m load(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentry_point)\n\u001b[1;32m---> 76\u001b[0m     env \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n\u001b[0;32m     78\u001b[0m \u001b[39m# Make the environment aware of which spec it came from.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m spec \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\minerl\\env\\core.py:137\u001b[0m, in \u001b[0;36mMineRLEnv.__init__\u001b[1;34m(self, xml, observation_space, action_space, env_spec, port, noop_action, docstr)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_step_time \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_already_closed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_new_instance(port)\n\u001b[0;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv_spec \u001b[39m=\u001b[39m env_spec\n\u001b[0;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space \u001b[39m=\u001b[39m observation_space\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\minerl\\env\\core.py:159\u001b[0m, in \u001b[0;36mMineRLEnv._get_new_instance\u001b[1;34m(self, port, instance_id)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m InstanceManager\u001b[39m.\u001b[39mis_remote():\n\u001b[0;32m    157\u001b[0m     launch_queue_logger_thread(instance, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_closed)\n\u001b[1;32m--> 159\u001b[0m instance\u001b[39m.\u001b[39;49mlaunch()\n\u001b[0;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m instance\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\minerl\\env\\malmo.py:469\u001b[0m, in \u001b[0;36mInstanceManager.Instance.launch\u001b[1;34m(self, daemonize)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_dir \u001b[39m=\u001b[39m tempfile\u001b[39m.\u001b[39mmkdtemp()\n\u001b[0;32m    468\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminecraft_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_dir, \u001b[39m'\u001b[39m\u001b[39mMinecraft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 469\u001b[0m shutil\u001b[39m.\u001b[39;49mcopytree(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(InstanceManager\u001b[39m.\u001b[39;49mMINECRAFT_DIR), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mminecraft_dir,\n\u001b[0;32m    470\u001b[0m                 ignore\u001b[39m=\u001b[39;49mshutil\u001b[39m.\u001b[39;49mignore_patterns(\u001b[39m'\u001b[39;49m\u001b[39mcache.properties.lock\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m    471\u001b[0m shutil\u001b[39m.\u001b[39mcopytree(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(InstanceManager\u001b[39m.\u001b[39mSCHEMAS_DIR), os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_dir, \u001b[39m'\u001b[39m\u001b[39mSchemas\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m    474\u001b[0m \u001b[39m# 0. Get PID of launcher.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\shutil.py:564\u001b[0m, in \u001b[0;36mcopytree\u001b[1;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[39m\"\"\"Recursively copy a directory tree and return the destination directory.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \n\u001b[0;32m    529\u001b[0m \u001b[39mdirs_exist_ok dictates whether to raise an exception in case dst or any\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    561\u001b[0m \n\u001b[0;32m    562\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mshutil.copytree\u001b[39m\u001b[39m\"\u001b[39m, src, dst)\n\u001b[1;32m--> 564\u001b[0m \u001b[39mwith\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(src) \u001b[39mas\u001b[39;00m itr:\n\u001b[0;32m    565\u001b[0m     entries \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itr)\n\u001b[0;32m    566\u001b[0m \u001b[39mreturn\u001b[39;00m _copytree(entries\u001b[39m=\u001b[39mentries, src\u001b[39m=\u001b[39msrc, dst\u001b[39m=\u001b[39mdst, symlinks\u001b[39m=\u001b[39msymlinks,\n\u001b[0;32m    567\u001b[0m                  ignore\u001b[39m=\u001b[39mignore, copy_function\u001b[39m=\u001b[39mcopy_function,\n\u001b[0;32m    568\u001b[0m                  ignore_dangling_symlinks\u001b[39m=\u001b[39mignore_dangling_symlinks,\n\u001b[0;32m    569\u001b[0m                  dirs_exist_ok\u001b[39m=\u001b[39mdirs_exist_ok)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\gppl20\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\minerl\\\\env\\\\Malmo\\\\Minecraft'"
     ]
    }
   ],
   "source": [
    "def load_model_parameters(path_to_model_file):\n",
    "    agent_parameters = pickle.load(open(path_to_model_file, \"rb\"))\n",
    "    policy_kwargs = agent_parameters[\"model\"][\"args\"][\"net\"][\"args\"]\n",
    "    pi_head_kwargs = agent_parameters[\"model\"][\"args\"][\"pi_head_opts\"]\n",
    "    pi_head_kwargs[\"temperature\"] = float(pi_head_kwargs[\"temperature\"])\n",
    "\n",
    "    return policy_kwargs, pi_head_kwargs\n",
    "\n",
    "from agent import PI_HEAD_KWARGS, MineRLAgent\n",
    "\n",
    "agent_policy_kwargs, agent_pi_head_kwargs = load_model_parameters(\"2x.model\")\n",
    "\n",
    "env = gym.make(\"MineRLNavigate-v0\")  # MineRLObtainTest-v0  #'MineRLTreechop-v0' #MINERL_NAVIGATE_V0 #MINERL_OBTAIN_DIAMOND_V0 #MINERL_OBTAIN_IRON_PICKAXE_V0 #\"MineRLBasaltFindCave-v0\"\n",
    "agent = MineRLAgent(env=env, device=DEVICE, policy_kwargs=agent_policy_kwargs, pi_head_kwargs=agent_pi_head_kwargs)\n",
    "env.close()\n",
    "policy = agent.policy\n",
    "trainable_parameters = policy.parameters()\n",
    "\n",
    "print(policy.net.hidsize)\n",
    "print(agent_policy_kwargs)\n",
    "\n",
    "from agent import PI_HEAD_KWARGS, MineRLAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\VLPT\\VLPT\\VLPT explorer.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VLPT/VLPT/VLPT%20explorer.ipynb#ch0000004?line=25'>26</a>\u001b[0m words \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtoken_ids\u001b[39m\u001b[39m'\u001b[39m:th\u001b[39m.\u001b[39mcat([tokenA,tokenB],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\u001b[39m'\u001b[39m\u001b[39mms\u001b[39m\u001b[39m'\u001b[39m: th\u001b[39m.\u001b[39mzeros([bsz,seq_len\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m])}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VLPT/VLPT/VLPT%20explorer.ipynb#ch0000004?line=26'>27</a>\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/VLPT/VLPT/VLPT%20explorer.ipynb#ch0000004?line=27'>28</a>\u001b[0m     pi_latent, vf_latent, LM_words, VPT_state, LM_state_out, LM_loss \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39mget_output_for_observations(ob_frames\u001b[39m=\u001b[39mframes, ob_words\u001b[39m=\u001b[39mwords, LM_active_timestep\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'policy' is not defined"
     ]
    }
   ],
   "source": [
    "# TEST POLICY RECURRENT/TRANSFORMER BEHAVIOUR\n",
    "seq_len = 1\n",
    "bsz = 1\n",
    "frameA = th.normal(0,1,[bsz,seq_len,128,128,3])\n",
    "frameB = th.normal(0,1,[bsz,seq_len,128,128,3])\n",
    "tokenA = th.full([bsz,seq_len],4127, dtype=th.long)\n",
    "tokenB = th.full([bsz,seq_len],3467, dtype=th.long)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# get output for input P(A) -> P(B)\n",
    "frames = {'img':frameA,'ms': th.zeros([bsz,seq_len])}\n",
    "words = {'token_ids':tokenA,'ms': th.zeros([bsz,seq_len])}\n",
    "with th.no_grad():\n",
    "    pi_latent, vf_latent, LM_words, VPT_state, LM_state_out, LM_loss = agent.policy.get_output_for_observations(ob_frames=frames, ob_words=words, LM_active_timestep=True)\n",
    "frames = {'img':frameB,'ms': th.zeros([bsz,seq_len])}\n",
    "print(pi_latent['camera'])\n",
    "words = {'token_ids':tokenB,'ms': th.zeros([bsz,seq_len])}\n",
    "with th.no_grad():\n",
    "    pi_latent, vf_latent, LM_words, VPT_state_out, LM_state_out, LM_loss = agent.policy.get_output_for_observations(ob_frames=frames, ob_words=words, LM_active_timestep=True, VPT_state=VPT_state, LM_state=LM_state_out)\n",
    "print(pi_latent['camera'])\n",
    "\"\"\"\n",
    "\n",
    "# get output for input P(A,B)\n",
    "frames = {'img':th.cat([frameA,frameB],axis=1),'ms': th.zeros([bsz,seq_len*2])}\n",
    "words = {'token_ids':th.cat([tokenA,tokenB],axis=1),'ms': th.zeros([bsz,seq_len*2])}\n",
    "with th.no_grad():\n",
    "    pi_latent, vf_latent, LM_words, VPT_state, LM_state_out, LM_loss = policy.get_output_for_observations(ob_frames=frames, ob_words=words, LM_active_timestep=True)\n",
    "#print(pi_latent['camera'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "for fwd in range(256//128):\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   16, 12963],\n",
       "        [   16, 12963],\n",
       "        [   16, 12963]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM_words.shape\n",
    "th.argmax(LM_words, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in forward. x shape: torch.Size([2, 1, 128, 128, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idmi/miniconda3/envs/minerl/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in forward. x shape: torch.Size([2, 1, 4096])\n",
      "shape of IDM predict output: {'buttons': tensor([[[0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0]]]), 'camera': tensor([[[3, 2]],\n",
      "\n",
      "        [[5, 4]]])}\n",
      "hidden state: [(None, (tensor([], size=(2, 0, 4096)), tensor([], size=(2, 0, 4096)))), (None, (tensor([], size=(2, 0, 4096)), tensor([], size=(2, 0, 4096))))]\n"
     ]
    }
   ],
   "source": [
    "# TEST IDM BEHAVIOUR\n",
    "\n",
    "from inverse_dynamics_model import IDMAgent\n",
    "\n",
    "agent_parameters = pickle.load(open('4x_idm.model', \"rb\"))\n",
    "net_kwargs = agent_parameters[\"model\"][\"args\"][\"net\"][\"args\"]\n",
    "pi_head_kwargs = agent_parameters[\"model\"][\"args\"][\"pi_head_opts\"]\n",
    "pi_head_kwargs[\"temperature\"] = float(pi_head_kwargs[\"temperature\"])\n",
    "agent = IDMAgent(device=DEVICE, idm_net_kwargs=net_kwargs, pi_head_kwargs=pi_head_kwargs)\n",
    "\n",
    "first = th.from_numpy(np.array((False,))).to(DEVICE)\n",
    "\n",
    "#frames = [np.random.normal(0,0.02,(128,128,3)),  np.random.normal(0,0.02,(128,128,3)),  np.random.normal(0,0.02,(128,128,3))]\n",
    "\n",
    "frames = np.random.normal(0,0.02,(2,1,128,128,3))\n",
    "ac = agent.predict_actions(frames, raw_frames=True) # test for frames=1 and n_frames=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ac' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(ac[\u001b[39m'\u001b[39m\u001b[39mcamera\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ac' is not defined"
     ]
    }
   ],
   "source": [
    "print(ac['camera'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# TEST X-ATTN\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ob_frames \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mones((\u001b[39m128\u001b[39m,\u001b[39m128\u001b[39m,\u001b[39m3\u001b[39m))\u001b[39m*\u001b[39m\u001b[39m0.01\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)]\n\u001b[0;32m----> 4\u001b[0m ob_frames \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39m_video_obs_to_agent( ob_frames )\n\u001b[1;32m      5\u001b[0m ob_frames[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m,:,:,:,:] \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mones([\u001b[39m10\u001b[39m,\u001b[39m128\u001b[39m,\u001b[39m128\u001b[39m,\u001b[39m3\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m-\u001b[39m\u001b[39m0.05\u001b[39m\n\u001b[1;32m      6\u001b[0m ob_words \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39m_words_to_agent(\u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm going to count to 10: 1, 2, 3, 4, 5, 6, 7, 8, \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "# TEST X-ATTN\n",
    "\n",
    "ob_frames = [np.ones((128,128,3))*0.01 for i in range(10)]\n",
    "ob_frames = agent._video_obs_to_agent( ob_frames )\n",
    "ob_frames['img'][0,:,:,:,:] = th.ones([10,128,128,3])*-0.05\n",
    "ob_words = agent._words_to_agent(\"I'm going to count to 10: 1, 2, 3, 4, 5, 6, 7, 8, \")\n",
    "\n",
    "policy.net.Xattn_VPT_LM.alpha_xattn=th.nn.Parameter(th.tensor(0.))\n",
    "policy.net.Xattn_VPT_LM.alpha_xattn=th.nn.Parameter(th.tensor(0.))\n",
    "\n",
    "action_prob, action, pd_word = policy.get_output_for_observations(ob_words=ob_words, ob_frames=ob_frames) # test for frames=1 and n_frames=2\n",
    "print(pd_word.mean(), pd_word.std())\n",
    "\n",
    "\n",
    "token_index = th.argmax(pd_word[0,-1,:]).item()\n",
    "\n",
    "print(agent._agent_words_to_string(token_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVhoKnqVM5Fd"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "# Needs to be <= number of videos\n",
    "BATCH_SIZE = 8\n",
    "# Ideally more than batch size to create\n",
    "# variation in datasets (otherwise, you will\n",
    "# get a bunch of consecutive samples)\n",
    "# Decrease this (and batch_size) if you run out of memory\n",
    "N_WORKERS = 12\n",
    "LOSS_REPORT_RATE = 100\n",
    "LEARNING_RATE = 0.000181\n",
    "WEIGHT_DECAY = 0.039428\n",
    "MAX_GRAD_NORM = 5.0\n",
    "# Basic behavioural cloning\n",
    "# Note: this uses gradient accumulation in batches of ones\n",
    "#       to perform training.\n",
    "#       This will fit inside even smaller GPUs (tested on 8GB one),\n",
    "#       but is slow.\n",
    "# NOTE: This is _not_ the original code used for VPT!\n",
    "#       This is merely to illustrate how to fine-tune the models and includes\n",
    "#       the processing steps used.                                               @FIX THIS to run on 4x3090 = 96GB:\n",
    "\n",
    "# This will likely be much worse than what original VPT did:\n",
    "# we are not training on full sequences, but only one step at a time to save VRAM.\n",
    "def behavioural_cloning_train(data_dir, in_model, in_weights, out_weights):\n",
    "    agent_policy_kwargs, agent_pi_head_kwargs = load_model_parameters(in_model)\n",
    "\n",
    "    # To create model with the right environment.\n",
    "    # All basalt environments have the same settings, so any of them works here\n",
    "    env = gym.make(\"MineRLBasaltFindCave-v0\")\n",
    "    agent = MineRLAgent(env, device=DEVICE, policy_kwargs=agent_policy_kwargs, pi_head_kwargs=agent_pi_head_kwargs)\n",
    "    agent.load_weights(in_weights)\n",
    "    env.close()\n",
    "\n",
    "    policy = agent.policy\n",
    "    trainable_parameters = policy.parameters()\n",
    "\n",
    "    # Parameters taken from the OpenAI VPT paper\n",
    "    optimizer = th.optim.Adam(\n",
    "        trainable_parameters,\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset_dir=data_dir,\n",
    "        n_workers=N_WORKERS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        n_epochs=EPOCHS\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Keep track of the hidden state per episode/trajectory.\n",
    "    # DataLoader provides unique id for each episode, which will\n",
    "    # be different even for the same trajectory when it is loaded\n",
    "    # up again\n",
    "    episode_hidden_states = {}\n",
    "    dummy_first = th.from_numpy(np.array((False,))).to(DEVICE)\n",
    "\n",
    "    loss_sum = 0\n",
    "    for batch_i, (batch_images, batch_actions, batch_episode_id) in enumerate(data_loader):\n",
    "        batch_loss = 0\n",
    "        for image, action, episode_id in zip(batch_images, batch_actions, batch_episode_id):\n",
    "            \n",
    "            agent_action = agent._env_action_to_agent(action, to_torch=True, check_if_null=True)\n",
    "            \n",
    "            if agent_action is None:\n",
    "                # Action was null\n",
    "                continue\n",
    "\n",
    "            agent_obs = agent._video_obs_to_agent({\"pov\": image})\n",
    "\n",
    "            if episode_id not in episode_hidden_states:\n",
    "                # TODO need to clean up this hidden state after worker is done with the work item.\n",
    "                #      Leaks memory, but not tooooo much at these scales (will be a problem later).\n",
    "                episode_hidden_states[episode_id] = policy.initial_state(1)\n",
    "            agent_state = episode_hidden_states[episode_id]\n",
    "            \n",
    "            pi_distribution, v_prediction, new_agent_state, word_pd, word_v = policy.get_output_for_observations(\n",
    "                ob_frames = agent_obs,\n",
    "                ob_words = ob_words,\n",
    "                VPT_state_in = agent_state,\n",
    "                dummy_first = None\n",
    "            )\n",
    "\n",
    "            if (LM_full):\n",
    "                loss = \n",
    "\n",
    "\n",
    "            # ACTION LOSS\n",
    "            log_prob  = policy.get_logprob_of_action(pi_distribution, agent_action)\n",
    "\n",
    "\n",
    "            # LANGUAGE LOSS - from modeling_opt.py\n",
    "            logits = word_pd.contiguous()\n",
    "            labels = th.full([word_pd.shape[0],word_pd.shape[1],1], -100, dtype=th.LongTensor) # dont compute loss for masked tokens (hence -100 token ids for masked tokens, as per OPT)\n",
    "            for b in range(len(ob_words['input_ids'])):\n",
    "                n_tokens = len(ob_words['input_ids'][b])\n",
    "                labels[:n_tokens] = ob_words['input_ids']\n",
    "            loss = None\n",
    "            # Shift so that tokens < n predict n\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()      #@ make sure to not train \n",
    "            # Flatten the tokens\n",
    "            loss_fct = th.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, policy.net.LM.model.decoder.vocab_size), shift_labels.view(-1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Make sure we do not try to backprop through sequence\n",
    "            # (fails with current accumulation)\n",
    "            new_agent_state = tree_map(lambda x: x.detach(), new_agent_state)\n",
    "            episode_hidden_states[episode_id] = new_agent_state\n",
    "\n",
    "            # Finally, update the agent to increase the probability of the\n",
    "            # taken action.\n",
    "            # Remember to take mean over batch losses\n",
    "            loss = -log_prob / BATCH_SIZE\n",
    "            batch_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "        th.nn.utils.clip_grad_norm_(trainable_parameters, MAX_GRAD_NORM)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += batch_loss\n",
    "        if batch_i % LOSS_REPORT_RATE == 0:\n",
    "            time_since_start = time.time() - start_time\n",
    "            print(f\"Time: {time_since_start:.2f}, Batches: {batch_i}, Avrg loss: {loss_sum / LOSS_REPORT_RATE:.4f}\")\n",
    "            loss_sum = 0\n",
    "\n",
    "    state_dict = policy.state_dict()\n",
    "    th.save(state_dict, out_weights)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "attention_heads': 16,\n",
    "  'attention_mask_style': 'clipped_causal',\n",
    "  'attention_memory_size': 256,\n",
    "  'diff_mlp_embedding': False,\n",
    "  'hidsize': 2048,\n",
    "  'img_shape': [128, 128, 3],\n",
    "  'impala_chans': [16, 32, 32],\n",
    "  'impala_kwargs': {'post_pool_groups': 1},\n",
    "  'impala_width': 8,\n",
    "  'init_norm_kwargs': {'batch_norm': False, 'group_norm_groups': 1},\n",
    "  'n_recurrence_layers': 4,\n",
    "  'only_img_input': True,\n",
    "  'pointwise_ratio': 4,\n",
    "  'pointwise_use_activation': False,\n",
    "  'recurrence_is_residual': True,\n",
    "  'recurrence_type': 'transformer',\n",
    "  'timesteps': 128,\n",
    "  'use_pointwise_layer': True,\n",
    "  'use_pre_lstm_ln': False},\n",
    "\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = th.nn.MultiheadAttention(\n",
    "            embed_dim=512,  # in pytorch, its split across heads\n",
    "            num_heads=16,\n",
    "            dropout=0.0,\n",
    "            bias=True,\n",
    "            add_bias_kv=False,\n",
    "            add_zero_attn=False,\n",
    "            kdim=128*16,vdim=128*16,\n",
    "            batch_first=True,\n",
    "            device=DEVICE,\n",
    "            dtype=th.float32)\n",
    "\n",
    "tokensL = th.normal(0,0.02,[2,4,512])\n",
    "tokensV = th.normal(0,0.02,[2,5,2048])\n",
    "\n",
    "attn_mask = th.zeros([4,5])\n",
    "attn_mask[-1,:] = 1\n",
    "print(attn_mask)\n",
    "\n",
    "out = attention(query=tokensL, key=tokensV, value=tokensV, attn_mask=attn_mask)\n",
    "print(out)\n",
    "th.isnan(out[0]).any()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMW0NSERlVQQUPphW+YKITN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
