{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2969,
     "status": "ok",
     "timestamp": 1669722448788,
     "user": {
      "displayName": "Idmi",
      "userId": "02220947904692487762"
     },
     "user_tz": 0
    },
    "id": "nbezCFQUbal_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CPU\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import sys, os\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "import minerl\n",
    "\n",
    "#from data_loader import DataLoader\n",
    "from lib.tree_util import tree_map\n",
    "\n",
    "if th.cuda.is_available():\n",
    "    DEVICE = th.device('cuda')\n",
    "    print(\"USING CUDA\")\n",
    "else:\n",
    "\n",
    "    DEVICE = th.device('cpu')\n",
    "    print(\"USING CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TransfoXLTokenizer\n",
    "text = \"Well, if my name were Daniel, I would certainly not be joking about it so much. As it stands, I am not names Daniel, and so find it perfectly apt to mock you.\"\n",
    "\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained(\"transfo-xl-wt103\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([240])\n",
      "1 torch.Size([240])\n",
      "2 torch.Size([48, 5])\n",
      "3 torch.Size([48, 5])\n",
      "final 12\n",
      "{'input_ids': tensor([[ 6415,     2,   222,   617,   237,    28,  2452,     2,    68,    61,\n",
      "          4867,    38,    35, 27875,    80,    29,   138,   220,     3,   147,\n",
      "            29,  3024,     2,    68,  2271,    38,  1302,  2452,     2,     5,\n",
      "           138,   767,    29,  7116, 28661,     6, 10966,   304,     3]])}\n",
      "Well, if my name were Daniel, I would certainly not be joking about it so much. As it stands, I am not names Daniel, and so find it perfectly apt to mock you.\n",
      "<eos>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m#LOAD LM\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m TransfoXLLMHeadModel\n\u001b[0;32m---> 64\u001b[0m model \u001b[39m=\u001b[39m TransfoXLLMHeadModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mtransfo-xl-wt103\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     67\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39md_embed)\n\u001b[1;32m     68\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mn_layer)\n",
      "File \u001b[0;32m~/miniconda3/envs/minerl/lib/python3.8/site-packages/transformers/modeling_utils.py:2230\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n\u001b[1;32m   2228\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sharded \u001b[39mand\u001b[39;00m state_dict \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2229\u001b[0m         \u001b[39m# Time to load the checkpoint\u001b[39;00m\n\u001b[0;32m-> 2230\u001b[0m         state_dict \u001b[39m=\u001b[39m load_state_dict(resolved_archive_file)\n\u001b[1;32m   2232\u001b[0m     \u001b[39m# set dtype to instantiate the model under:\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[39m# 1. If torch_dtype is not None, we use that dtype\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[39m# 2. If torch_dtype is \"auto\", we auto-detect dtype from the loaded state_dict, by checking its first\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[39m#    weights entry that is of a floating type - we assume all floating dtype weights are of the same dtype\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     \u001b[39m# we also may have config.torch_dtype available, but we won't rely on it till v5\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m     dtype_orig \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/minerl/lib/python3.8/site-packages/transformers/modeling_utils.py:399\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_load_file(checkpoint_file)\n\u001b[1;32m    398\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(checkpoint_file, map_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    400\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    401\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/minerl/lib/python3.8/site-packages/torch/serialization.py:608\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[1;32m    607\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 608\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/minerl/lib/python3.8/site-packages/torch/serialization.py:794\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m deserialized_storage_keys:\n\u001b[1;32m    793\u001b[0m     \u001b[39massert\u001b[39;00m key \u001b[39min\u001b[39;00m deserialized_objects\n\u001b[0;32m--> 794\u001b[0m     deserialized_objects[key]\u001b[39m.\u001b[39;49m_set_from_file(f, offset, f_should_read_directly)\n\u001b[1;32m    795\u001b[0m     \u001b[39mif\u001b[39;00m offset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m         offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = \"\"\"= = Distribution = =\n",
    "Species range across the Neotropics from Mexico in the north to Bolivia, Paraguay, and southern Brazil in the south. According to <unk> and coauthors, three\n",
    "species are found in Mexico, four in Central America, and 62 in South America. Three species are present in the Caribbean â€” two in Trinidad and Tobago, along\n",
    "the southern edge of the region, and one in Haiti.\"\"\"\n",
    "import numpy as np\n",
    "path = 'text.txt'\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        if True and idx > 0 and idx % 500000 == 0:\n",
    "            pass\n",
    "            #print('    line {}'.format(idx))\n",
    "        #print('LINE',line)\n",
    "\n",
    "\n",
    "data = th.LongTensor(np.arange(5*16*3))\n",
    "\n",
    "bsz = 5\n",
    "bptt = 4\n",
    "ext_len = 0\n",
    "\n",
    "# Work out how cleanly we can divide the dataset into bsz parts.\n",
    "print('0',data.shape)\n",
    "n_step = data.size(0) // bsz\n",
    "\n",
    "# Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "data = data.narrow(0, 0, n_step * bsz)\n",
    "print('1',data.shape)\n",
    "\n",
    "\n",
    "# Evenly divide the data across the bsz batches.\n",
    "data = data.view(bsz, -1).t().contiguous()\n",
    "print('2',data.shape)\n",
    "\n",
    "# Number of mini-batches\n",
    "n_batch = (n_step + bptt - 1) // bptt\n",
    "print('3',data.shape)\n",
    "\n",
    "print('final', n_batch)\n",
    "\n",
    "# LOAD TOKENIZER\n",
    "from transformers import TransfoXLTokenizer\n",
    "text = \"Well, if my name were Daniel, I would certainly not be joking about it so much. As it stands, I am not names Daniel, and so find it perfectly apt to mock you.\"\n",
    "\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained(\"transfo-xl-wt103\")\n",
    "## TEST TOKENIZER\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "n_tokens = inputs['input_ids'].shape[1]\n",
    "print(inputs)\n",
    "inputs_list = inputs['input_ids'].reshape([n_tokens]).tolist()\n",
    "print(tokenizer.decode(inputs_list))\n",
    "print(tokenizer.decode([0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#LOAD LM\n",
    "from transformers import TransfoXLLMHeadModel\n",
    "model = TransfoXLLMHeadModel.from_pretrained(\"transfo-xl-wt103\")\n",
    "\n",
    "\n",
    "print(model.transformer.d_embed)\n",
    "print(model.transformer.n_layer)\n",
    "print(model.transformer.n_head)\n",
    "print(model.transformer.d_model)\n",
    "print(model.transformer.config.bos_token_id)\n",
    "print(model.transformer.config.vocab_size)\n",
    "print(model.sample_softmax)\n",
    "print(model.transformer.config.div_val)\n",
    "print(model.transformer.word_emb)\n",
    "print(model.transformer.word_emb)\n",
    "\n",
    "print(model.config.torchscript)\n",
    "print(model.trainer_compatible)\n",
    "\n",
    "\n",
    "print(model.num_parameters())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#outputs = model(inputs_embeds=torch.normal(0,1,[1,5,1024]))\n",
    "input_ids = th.tensor([[6415,     2,   222,   617,   237,    28,  2452,     2,    68,    61,\n",
    "          4867,    38,    35, 27875,    80,    29,   138,   220,     3,   147,\n",
    "            29,  3024,     2,    68,  2271,    38,  1302,  2452,     2,     5,\n",
    "           138,   767,    29,  7116, 28661,     6, 10966,   304,     3]],\n",
    "            dtype=th.long)\n",
    "\n",
    "outputs = model(input_ids=input_ids, labels=input_ids.roll(1, dims=1))\n",
    "#outputs2 = model(input_ids=input_ids, labels=input_ids)\n",
    "\n",
    "#\n",
    "\n",
    "#print(tokenizer.decode(outputs.prediction_scores[0,5,1000]))\n",
    "\n",
    "\n",
    "\n",
    "#print(outputs)\n",
    "print(outputs.logits)\n",
    "print(outputs.loss)\n",
    "\n",
    "\n",
    "maxes = th.argmax(outputs.logits, axis=1)\n",
    "print(input_ids.shape)\n",
    "print(maxes.shape)\n",
    "print(tokenizer.decode(input_ids[0]),\"\\n\")\n",
    "print(tokenizer.decode(maxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "error",
     "timestamp": 1669722218180,
     "user": {
      "displayName": "Idmi",
      "userId": "02220947904692487762"
     },
     "user_tz": 0
    },
    "id": "Wfv11S7AjPbo",
    "outputId": "dea05d6d-d32f-4dbd-fbf1-398affc96078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: USING CUSTOM TRANSFORMER_XL UTILITIES.py. DO NOT USE THE LMHEAD.FORWAD() METHOD IWTH LABELS, IT WILL GIVE INCORRECT LOSS AND PREDICTIONS\n",
      "2048\n",
      "{'active_reward_monitors': {'craft_stats': {'args': {'collapse_var': True, 'items': ['planks', 'stick', 'crafting_table', 'wooden_pickaxe', 'stone_pickaxe', 'furnace', 'iron_ingot', 'iron_pickaxe', 'diamond_pickaxe', 'torch']}, 'weight': 0}, 'mine_stats': {'args': {'collapse_var': True, 'items': ['log', 'coal_ore', 'stone', 'iron_ore', 'diamond_ore', 'obsidian']}, 'weight': 0}, 'order_invariant_curriculum': {'args': {'curriculum': {'coal': [5, 0.4], 'cobblestone': [11, 0.09090909090909091], 'crafting_table': [1, 1], 'diamond': [10000, 2.6666666666666665], 'diamond_pickaxe': [10000, 8], 'furnace': [1, 1], 'iron_ingot': [3, 1.3333333333333333], 'iron_ore': [3, 1.3333333333333333], 'iron_pickaxe': [1, 4], 'log': [8, 0.125], 'obsidian': [10000, 16], 'planks': [20, 0.05], 'stick': [16, 0.0625], 'stone_pickaxe': [1, 1], 'torch': [16, 0.125], 'wooden_pickaxe': [1, 1]}}, 'weight': 1}, 'pickup_stats': {'args': {'collapse_var': True, 'items': ['log', 'coal', 'cobblestone', 'iron_ore', 'diamond']}, 'weight': 0}, 'variety': {'args': {'collapse_var': True, 'included_items': ['beef', 'chicken', 'leather', 'mutton', 'porkchop', 'bucket', 'milk_bucket', 'water_bucket', 'coal', 'crafting_table', 'furnace', 'diamond', 'gold_ingot', 'gold_ore', 'flint', 'iron_ingot', 'iron_ore', 'shears', 'string', 'cobblestone', 'log', 'planks', 'stick', 'wool', 'obsidian', 'paper', 'redstone', 'wheat', 'cooked_beef', 'cooked_chicken', 'cooked_mutton', 'cooked_porkchop', 'egg', 'feather', 'leather_boots', 'leather_chestplate', 'leather_helmet', 'leather_leggings', 'brick', 'brick_stairs', 'clay', 'clay_ball', 'flower_pot', 'terracotta', 'torch', 'diamond_axe', 'diamond_block', 'diamond_boots', 'diamond_chestplate', 'diamond_helmet', 'diamond_hoe', 'diamond_leggings', 'diamond_pickaxe', 'diamond_shovel', 'diamond_sword', 'dirt', 'golden_apple', 'golden_axe', 'golden_boots', 'golden_chestplate', 'golden_helmet', 'golden_hoe', 'golden_leggings', 'golden_pickaxe', 'golden_shovel', 'golden_sword', 'arrow', 'gravel', 'iron_axe', 'iron_boots', 'iron_chestplate', 'iron_helmet', 'iron_hoe', 'iron_leggings', 'iron_pickaxe', 'iron_shovel', 'iron_sword', 'shield', 'fermented_spider_eye', 'leaves', 'apple', 'bread', 'activator_rail', 'clock', 'compass', 'detector_rail', 'dropper', 'book', 'bookshelf', 'cake', 'filled_map', 'sugar_cane', 'sugar', 'bow', 'dispenser', 'fishing_rod', 'spider_eye', 'stone_axe', 'stone_hoe', 'stone_pickaxe', 'stone_shovel', 'stone_sword', 'boat', 'wooden_axe', 'wooden_hoe', 'wooden_pickaxe', 'wooden_shovel', 'wooden_sword', 'banner', 'bed', 'carpet', 'map', 'redstone_torch', 'wheat_seeds', 'flint_and_steel']}, 'weight': 0}}, 'attention_heads': 16, 'attention_mask_style': 'clipped_causal', 'attention_memory_size': 256, 'diff_mlp_embedding': False, 'hidsize': 2048, 'img_shape': [128, 128, 3], 'impala_chans': [16, 32, 32], 'impala_kwargs': {'post_pool_groups': 1}, 'impala_width': 8, 'init_norm_kwargs': {'batch_norm': False, 'group_norm_groups': 1}, 'n_recurrence_layers': 4, 'only_img_input': True, 'pointwise_ratio': 4, 'pointwise_use_activation': False, 'recurrence_is_residual': True, 'recurrence_type': 'transformer', 'timesteps': 128, 'use_pointwise_layer': True, 'use_pre_lstm_ln': False}\n"
     ]
    }
   ],
   "source": [
    "def load_model_parameters(path_to_model_file):\n",
    "    agent_parameters = pickle.load(open(path_to_model_file, \"rb\"))\n",
    "    policy_kwargs = agent_parameters[\"model\"][\"args\"][\"net\"][\"args\"]\n",
    "    pi_head_kwargs = agent_parameters[\"model\"][\"args\"][\"pi_head_opts\"]\n",
    "    pi_head_kwargs[\"temperature\"] = float(pi_head_kwargs[\"temperature\"])\n",
    "\n",
    "    return policy_kwargs, pi_head_kwargs\n",
    "\n",
    "from agent import PI_HEAD_KWARGS, MineRLAgent\n",
    "\n",
    "agent_policy_kwargs, agent_pi_head_kwargs = load_model_parameters(\"2x.model\")\n",
    "\n",
    "env = gym.make(\"MineRLBasaltFindCave-v0\")\n",
    "agent = MineRLAgent(env, device=DEVICE, policy_kwargs=agent_policy_kwargs, pi_head_kwargs=agent_pi_head_kwargs)\n",
    "env.close()\n",
    "policy = agent.policy\n",
    "trainable_parameters = policy.parameters()\n",
    "\n",
    "print(policy.net.hidsize)\n",
    "print(agent_policy_kwargs)\n",
    "\n",
    "from agent import PI_HEAD_KWARGS, MineRLAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered BLC forward\n",
      "CNN:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idmi/miniconda3/envs/minerl/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLPT1:\n",
      "seq lrn 256\n",
      "VPT1in: (None, (tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])))\n",
      "x in torch.Size([1, 128, 2048])\n",
      "VPT1out: (tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True]]]), (tensor([[[-0.1308, -0.1979, -0.1454,  ...,  0.0607, -0.1226, -0.0544],\n",
      "         [ 0.1041,  0.0994, -0.1523,  ..., -0.0841,  0.1125, -0.1160],\n",
      "         [-0.6165, -0.1647,  0.3022,  ...,  0.4780,  0.1041, -0.3326],\n",
      "         ...,\n",
      "         [ 0.0088,  0.1271, -0.1099,  ..., -0.1215, -0.1748, -0.0967],\n",
      "         [ 0.4072, -0.0287, -0.2804,  ..., -0.3227,  0.0022, -0.2011],\n",
      "         [-0.1419, -0.0621, -0.0225,  ..., -0.1350, -0.2947, -0.1702]]]), tensor([[[-0.5074, -0.2404, -1.1168,  ...,  0.3267,  0.0535, -0.5075],\n",
      "         [-0.1252, -0.1828, -0.2795,  ..., -0.1569, -0.0093, -0.7060],\n",
      "         [ 0.0725,  0.6289,  0.2454,  ..., -1.1337, -0.4425, -0.3533],\n",
      "         ...,\n",
      "         [ 0.7382,  0.2610, -0.1025,  ..., -0.2952, -0.7105, -0.7231],\n",
      "         [ 0.8643, -0.2392, -0.3190,  ..., -0.3559, -0.5622, -1.0758],\n",
      "         [ 0.1596, -0.5676, -0.5664,  ..., -0.2406, -0.1214,  0.1345]]])))\n",
      "temp: torch.Size([1, 128, 2048])\n",
      "VPT1in: (tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True]]]), (tensor([[[-0.1308, -0.1979, -0.1454,  ...,  0.0607, -0.1226, -0.0544],\n",
      "         [ 0.1041,  0.0994, -0.1523,  ..., -0.0841,  0.1125, -0.1160],\n",
      "         [-0.6165, -0.1647,  0.3022,  ...,  0.4780,  0.1041, -0.3326],\n",
      "         ...,\n",
      "         [ 0.0088,  0.1271, -0.1099,  ..., -0.1215, -0.1748, -0.0967],\n",
      "         [ 0.4072, -0.0287, -0.2804,  ..., -0.3227,  0.0022, -0.2011],\n",
      "         [-0.1419, -0.0621, -0.0225,  ..., -0.1350, -0.2947, -0.1702]]]), tensor([[[-0.5074, -0.2404, -1.1168,  ...,  0.3267,  0.0535, -0.5075],\n",
      "         [-0.1252, -0.1828, -0.2795,  ..., -0.1569, -0.0093, -0.7060],\n",
      "         [ 0.0725,  0.6289,  0.2454,  ..., -1.1337, -0.4425, -0.3533],\n",
      "         ...,\n",
      "         [ 0.7382,  0.2610, -0.1025,  ..., -0.2952, -0.7105, -0.7231],\n",
      "         [ 0.8643, -0.2392, -0.3190,  ..., -0.3559, -0.5622, -1.0758],\n",
      "         [ 0.1596, -0.5676, -0.5664,  ..., -0.2406, -0.1214,  0.1345]]])))\n",
      "x in torch.Size([1, 128, 2048])\n",
      "VPT1out: (tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True]]]), (tensor([[[ 0.3568,  0.1683, -0.1146,  ..., -0.0964, -0.0716, -0.1795],\n",
      "         [ 0.0215,  0.1651, -0.0349,  ..., -0.3113,  0.0089,  0.0373],\n",
      "         [-0.0290,  0.3166, -0.0870,  ..., -0.0934,  0.1468, -0.1693],\n",
      "         ...,\n",
      "         [-0.0294, -0.2020, -0.2758,  ..., -0.2003, -0.1144,  0.4323],\n",
      "         [ 0.1855,  0.0505, -0.5802,  ..., -0.0429, -0.1680, -0.1454],\n",
      "         [-0.0295, -0.0417, -0.1795,  ..., -0.1888, -0.1698, -0.2168]]]), tensor([[[-0.1920, -0.2103,  0.2731,  ...,  0.0955, -0.8612,  0.3394],\n",
      "         [ 0.1304, -1.3593, -0.7723,  ...,  0.6923, -0.5209, -0.1399],\n",
      "         [ 0.3015, -0.5984, -0.6315,  ..., -0.1250, -0.2778,  0.1384],\n",
      "         ...,\n",
      "         [ 0.1250,  0.2984, -0.7419,  ...,  0.3166, -0.0529, -0.3604],\n",
      "         [ 0.4038,  0.1237, -0.5634,  ..., -0.6027, -0.0797,  0.0757],\n",
      "         [ 0.2682, -0.8779, -0.3205,  ...,  0.1057, -0.7467, -0.8012]]])))\n",
      "temp: torch.Size([1, 128, 2048])\n",
      "X_: [tensor([[[-0.9834, -0.1524, -0.7505,  ...,  0.2977, -0.6304, -0.4411],\n",
      "         [-0.6856,  0.0845, -0.3812,  ...,  0.7654, -0.5644, -0.4276],\n",
      "         [-0.8754, -0.3910,  0.8891,  ...,  0.2330,  0.2223, -0.4650],\n",
      "         ...,\n",
      "         [-0.2444,  0.8833,  1.4464,  ..., -0.3552, -0.4674,  0.3836],\n",
      "         [-0.3992, -1.1707, -0.2265,  ..., -0.3254,  0.3052,  0.1279],\n",
      "         [ 1.1682, -0.8100, -0.1671,  ...,  3.5128,  2.0350,  2.1761]]]), tensor([[[ 2.0567, -0.4781,  0.3628,  ..., -0.5551,  1.7329, -0.8305],\n",
      "         [-0.6154, -0.2595,  0.1194,  ..., -0.8673,  2.1159, -0.3179],\n",
      "         [-0.8064,  0.0238, -0.5424,  ..., -0.8892,  0.4201, -0.6420],\n",
      "         ...,\n",
      "         [-0.7746, -0.7111, -0.2447,  ..., -0.4349, -1.0420, -0.6851],\n",
      "         [-0.7595, -0.7375,  3.1948,  ...,  0.4451, -0.4996, -0.8529],\n",
      "         [-0.9590, -0.1448, -0.6361,  ..., -0.9844, -0.1618, -0.5598]]])]\n",
      "tensor([[[-0.9834, -0.1524, -0.7505,  ...,  0.2977, -0.6304, -0.4411],\n",
      "         [-0.6856,  0.0845, -0.3812,  ...,  0.7654, -0.5644, -0.4276],\n",
      "         [-0.8754, -0.3910,  0.8891,  ...,  0.2330,  0.2223, -0.4650],\n",
      "         ...,\n",
      "         [-0.7746, -0.7111, -0.2447,  ..., -0.4349, -1.0420, -0.6851],\n",
      "         [-0.7595, -0.7375,  3.1948,  ...,  0.4451, -0.4996, -0.8529],\n",
      "         [-0.9590, -0.1448, -0.6361,  ..., -0.9844, -0.1618, -0.5598]]])\n",
      "xattn1 out shape torch.Size([1, 128, 1024])\n",
      "LM words shape torch.Size([1, 128, 267735])\n",
      "fused output= torch.Size([1, 256, 2048])\n",
      "WORDS SHAPE,  torch.Size([1, 128, 267735])\n"
     ]
    }
   ],
   "source": [
    "# TEST POLICY RECURRENT/TRANSFORMER BEHAVIOUR\n",
    "seq_len = 128\n",
    "bsz = 1\n",
    "frameA = th.normal(0,1,[bsz,seq_len,128,128,3])\n",
    "frameB = th.normal(0,1,[bsz,seq_len,128,128,3])\n",
    "tokenA = th.full([bsz,seq_len],4127, dtype=th.long)\n",
    "tokenB = th.full([bsz,seq_len],3467, dtype=th.long)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# get output for input P(A) -> P(B)\n",
    "frames = {'img':frameA,'ms': th.zeros([bsz,seq_len])}\n",
    "words = {'token_ids':tokenA,'ms': th.zeros([bsz,seq_len])}\n",
    "with th.no_grad():\n",
    "    pi_latent, vf_latent, LM_words, VPT_state, LM_state_out, LM_loss = agent.policy.get_output_for_observations(ob_frames=frames, ob_words=words, LM_active_timestep=True)\n",
    "frames = {'img':frameB,'ms': th.zeros([bsz,seq_len])}\n",
    "print(pi_latent['camera'])\n",
    "words = {'token_ids':tokenB,'ms': th.zeros([bsz,seq_len])}\n",
    "with th.no_grad():\n",
    "    pi_latent, vf_latent, LM_words, VPT_state_out, LM_state_out, LM_loss = agent.policy.get_output_for_observations(ob_frames=frames, ob_words=words, LM_active_timestep=True, VPT_state=VPT_state, LM_state=LM_state_out)\n",
    "print(pi_latent['camera'])\n",
    "\"\"\"\n",
    "\n",
    "# get output for input P(A,B)\n",
    "frames = {'img':th.cat([frameA,frameB],axis=1),'ms': th.zeros([bsz,seq_len*2])}\n",
    "words = {'token_ids':th.cat([tokenA,tokenB],axis=1),'ms': th.zeros([bsz,seq_len*2])}\n",
    "with th.no_grad():\n",
    "    pi_latent, vf_latent, LM_words, VPT_state, LM_state_out, LM_loss = agent.policy.get_output_for_observations(ob_frames=frames, ob_words=words, LM_active_timestep=True)\n",
    "#print(pi_latent['camera'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "for fwd in range(256//128):\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   16, 12963],\n",
       "        [   16, 12963],\n",
       "        [   16, 12963]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM_words.shape\n",
    "th.argmax(LM_words, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in forward. x shape: torch.Size([2, 1, 128, 128, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idmi/miniconda3/envs/minerl/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in forward. x shape: torch.Size([2, 1, 4096])\n",
      "shape of IDM predict output: {'buttons': tensor([[[0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0]]]), 'camera': tensor([[[3, 2]],\n",
      "\n",
      "        [[5, 4]]])}\n",
      "hidden state: [(None, (tensor([], size=(2, 0, 4096)), tensor([], size=(2, 0, 4096)))), (None, (tensor([], size=(2, 0, 4096)), tensor([], size=(2, 0, 4096))))]\n"
     ]
    }
   ],
   "source": [
    "# TEST IDM BEHAVIOUR\n",
    "\n",
    "from inverse_dynamics_model import IDMAgent\n",
    "\n",
    "agent_parameters = pickle.load(open('4x_idm.model', \"rb\"))\n",
    "net_kwargs = agent_parameters[\"model\"][\"args\"][\"net\"][\"args\"]\n",
    "pi_head_kwargs = agent_parameters[\"model\"][\"args\"][\"pi_head_opts\"]\n",
    "pi_head_kwargs[\"temperature\"] = float(pi_head_kwargs[\"temperature\"])\n",
    "agent = IDMAgent(device=DEVICE, idm_net_kwargs=net_kwargs, pi_head_kwargs=pi_head_kwargs)\n",
    "\n",
    "first = th.from_numpy(np.array((False,))).to(DEVICE)\n",
    "\n",
    "#frames = [np.random.normal(0,0.02,(128,128,3)),  np.random.normal(0,0.02,(128,128,3)),  np.random.normal(0,0.02,(128,128,3))]\n",
    "\n",
    "frames = np.random.normal(0,0.02,(2,1,128,128,3))\n",
    "ac = agent.predict_actions(frames, raw_frames=True) # test for frames=1 and n_frames=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ac' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(ac[\u001b[39m'\u001b[39m\u001b[39mcamera\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ac' is not defined"
     ]
    }
   ],
   "source": [
    "print(ac['camera'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# TEST X-ATTN\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ob_frames \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mones((\u001b[39m128\u001b[39m,\u001b[39m128\u001b[39m,\u001b[39m3\u001b[39m))\u001b[39m*\u001b[39m\u001b[39m0.01\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)]\n\u001b[0;32m----> 4\u001b[0m ob_frames \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39m_video_obs_to_agent( ob_frames )\n\u001b[1;32m      5\u001b[0m ob_frames[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m,:,:,:,:] \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mones([\u001b[39m10\u001b[39m,\u001b[39m128\u001b[39m,\u001b[39m128\u001b[39m,\u001b[39m3\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m-\u001b[39m\u001b[39m0.05\u001b[39m\n\u001b[1;32m      6\u001b[0m ob_words \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39m_words_to_agent(\u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm going to count to 10: 1, 2, 3, 4, 5, 6, 7, 8, \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "# TEST X-ATTN\n",
    "\n",
    "ob_frames = [np.ones((128,128,3))*0.01 for i in range(10)]\n",
    "ob_frames = agent._video_obs_to_agent( ob_frames )\n",
    "ob_frames['img'][0,:,:,:,:] = th.ones([10,128,128,3])*-0.05\n",
    "ob_words = agent._words_to_agent(\"I'm going to count to 10: 1, 2, 3, 4, 5, 6, 7, 8, \")\n",
    "\n",
    "policy.net.Xattn_VPT_LM.alpha_xattn=th.nn.Parameter(th.tensor(0.))\n",
    "policy.net.Xattn_VPT_LM.alpha_xattn=th.nn.Parameter(th.tensor(0.))\n",
    "\n",
    "action_prob, action, pd_word = policy.get_output_for_observations(ob_words=ob_words, ob_frames=ob_frames) # test for frames=1 and n_frames=2\n",
    "print(pd_word.mean(), pd_word.std())\n",
    "\n",
    "\n",
    "token_index = th.argmax(pd_word[0,-1,:]).item()\n",
    "\n",
    "print(agent._agent_words_to_string(token_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVhoKnqVM5Fd"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "# Needs to be <= number of videos\n",
    "BATCH_SIZE = 8\n",
    "# Ideally more than batch size to create\n",
    "# variation in datasets (otherwise, you will\n",
    "# get a bunch of consecutive samples)\n",
    "# Decrease this (and batch_size) if you run out of memory\n",
    "N_WORKERS = 12\n",
    "LOSS_REPORT_RATE = 100\n",
    "LEARNING_RATE = 0.000181\n",
    "WEIGHT_DECAY = 0.039428\n",
    "MAX_GRAD_NORM = 5.0\n",
    "# Basic behavioural cloning\n",
    "# Note: this uses gradient accumulation in batches of ones\n",
    "#       to perform training.\n",
    "#       This will fit inside even smaller GPUs (tested on 8GB one),\n",
    "#       but is slow.\n",
    "# NOTE: This is _not_ the original code used for VPT!\n",
    "#       This is merely to illustrate how to fine-tune the models and includes\n",
    "#       the processing steps used.                                               @FIX THIS to run on 4x3090 = 96GB:\n",
    "\n",
    "# This will likely be much worse than what original VPT did:\n",
    "# we are not training on full sequences, but only one step at a time to save VRAM.\n",
    "def behavioural_cloning_train(data_dir, in_model, in_weights, out_weights):\n",
    "    agent_policy_kwargs, agent_pi_head_kwargs = load_model_parameters(in_model)\n",
    "\n",
    "    # To create model with the right environment.\n",
    "    # All basalt environments have the same settings, so any of them works here\n",
    "    env = gym.make(\"MineRLBasaltFindCave-v0\")\n",
    "    agent = MineRLAgent(env, device=DEVICE, policy_kwargs=agent_policy_kwargs, pi_head_kwargs=agent_pi_head_kwargs)\n",
    "    agent.load_weights(in_weights)\n",
    "    env.close()\n",
    "\n",
    "    policy = agent.policy\n",
    "    trainable_parameters = policy.parameters()\n",
    "\n",
    "    # Parameters taken from the OpenAI VPT paper\n",
    "    optimizer = th.optim.Adam(\n",
    "        trainable_parameters,\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset_dir=data_dir,\n",
    "        n_workers=N_WORKERS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        n_epochs=EPOCHS\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Keep track of the hidden state per episode/trajectory.\n",
    "    # DataLoader provides unique id for each episode, which will\n",
    "    # be different even for the same trajectory when it is loaded\n",
    "    # up again\n",
    "    episode_hidden_states = {}\n",
    "    dummy_first = th.from_numpy(np.array((False,))).to(DEVICE)\n",
    "\n",
    "    loss_sum = 0\n",
    "    for batch_i, (batch_images, batch_actions, batch_episode_id) in enumerate(data_loader):\n",
    "        batch_loss = 0\n",
    "        for image, action, episode_id in zip(batch_images, batch_actions, batch_episode_id):\n",
    "            \n",
    "            agent_action = agent._env_action_to_agent(action, to_torch=True, check_if_null=True)\n",
    "            \n",
    "            if agent_action is None:\n",
    "                # Action was null\n",
    "                continue\n",
    "\n",
    "            agent_obs = agent._video_obs_to_agent({\"pov\": image})\n",
    "\n",
    "            if episode_id not in episode_hidden_states:\n",
    "                # TODO need to clean up this hidden state after worker is done with the work item.\n",
    "                #      Leaks memory, but not tooooo much at these scales (will be a problem later).\n",
    "                episode_hidden_states[episode_id] = policy.initial_state(1)\n",
    "            agent_state = episode_hidden_states[episode_id]\n",
    "            \n",
    "            pi_distribution, v_prediction, new_agent_state, word_pd, word_v = policy.get_output_for_observations(\n",
    "                ob_frames = agent_obs,\n",
    "                ob_words = ob_words,\n",
    "                VPT_state_in = agent_state,\n",
    "                dummy_first = None\n",
    "            )\n",
    "\n",
    "            if (LM_full):\n",
    "                loss = \n",
    "\n",
    "\n",
    "            # ACTION LOSS\n",
    "            log_prob  = policy.get_logprob_of_action(pi_distribution, agent_action)\n",
    "\n",
    "\n",
    "            # LANGUAGE LOSS - from modeling_opt.py\n",
    "            logits = word_pd.contiguous()\n",
    "            labels = th.full([word_pd.shape[0],word_pd.shape[1],1], -100, dtype=th.LongTensor) # dont compute loss for masked tokens (hence -100 token ids for masked tokens, as per OPT)\n",
    "            for b in range(len(ob_words['input_ids'])):\n",
    "                n_tokens = len(ob_words['input_ids'][b])\n",
    "                labels[:n_tokens] = ob_words['input_ids']\n",
    "            loss = None\n",
    "            # Shift so that tokens < n predict n\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()      #@ make sure to not train \n",
    "            # Flatten the tokens\n",
    "            loss_fct = th.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, policy.net.LM.model.decoder.vocab_size), shift_labels.view(-1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Make sure we do not try to backprop through sequence\n",
    "            # (fails with current accumulation)\n",
    "            new_agent_state = tree_map(lambda x: x.detach(), new_agent_state)\n",
    "            episode_hidden_states[episode_id] = new_agent_state\n",
    "\n",
    "            # Finally, update the agent to increase the probability of the\n",
    "            # taken action.\n",
    "            # Remember to take mean over batch losses\n",
    "            loss = -log_prob / BATCH_SIZE\n",
    "            batch_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "        th.nn.utils.clip_grad_norm_(trainable_parameters, MAX_GRAD_NORM)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += batch_loss\n",
    "        if batch_i % LOSS_REPORT_RATE == 0:\n",
    "            time_since_start = time.time() - start_time\n",
    "            print(f\"Time: {time_since_start:.2f}, Batches: {batch_i}, Avrg loss: {loss_sum / LOSS_REPORT_RATE:.4f}\")\n",
    "            loss_sum = 0\n",
    "\n",
    "    state_dict = policy.state_dict()\n",
    "    th.save(state_dict, out_weights)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "attention_heads': 16,\n",
    "  'attention_mask_style': 'clipped_causal',\n",
    "  'attention_memory_size': 256,\n",
    "  'diff_mlp_embedding': False,\n",
    "  'hidsize': 2048,\n",
    "  'img_shape': [128, 128, 3],\n",
    "  'impala_chans': [16, 32, 32],\n",
    "  'impala_kwargs': {'post_pool_groups': 1},\n",
    "  'impala_width': 8,\n",
    "  'init_norm_kwargs': {'batch_norm': False, 'group_norm_groups': 1},\n",
    "  'n_recurrence_layers': 4,\n",
    "  'only_img_input': True,\n",
    "  'pointwise_ratio': 4,\n",
    "  'pointwise_use_activation': False,\n",
    "  'recurrence_is_residual': True,\n",
    "  'recurrence_type': 'transformer',\n",
    "  'timesteps': 128,\n",
    "  'use_pointwise_layer': True,\n",
    "  'use_pre_lstm_ln': False},\n",
    "\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = th.nn.MultiheadAttention(\n",
    "            embed_dim=512,  # in pytorch, its split across heads\n",
    "            num_heads=16,\n",
    "            dropout=0.0,\n",
    "            bias=True,\n",
    "            add_bias_kv=False,\n",
    "            add_zero_attn=False,\n",
    "            kdim=128*16,vdim=128*16,\n",
    "            batch_first=True,\n",
    "            device=DEVICE,\n",
    "            dtype=th.float32)\n",
    "\n",
    "tokensL = th.normal(0,0.02,[2,4,512])\n",
    "tokensV = th.normal(0,0.02,[2,5,2048])\n",
    "\n",
    "attn_mask = th.zeros([4,5])\n",
    "attn_mask[-1,:] = 1\n",
    "print(attn_mask)\n",
    "\n",
    "out = attention(query=tokensL, key=tokensV, value=tokensV, attn_mask=attn_mask)\n",
    "print(out)\n",
    "th.isnan(out[0]).any()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMW0NSERlVQQUPphW+YKITN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('minerl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5771c508f711f7da473bf0954744d30385b19c5daa239986e839c4dfdaff2669"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
